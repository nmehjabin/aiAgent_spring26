{
  "timestamp": "20260119_041925",
  "device": "cpu",
  "quantization_bits": null,
  "num_subjects": 10,
  "subjects": [
    "abstract_algebra",
    "anatomy",
    "astronomy",
    "business_ethics",
    "clinical_knowledge",
    "college_biology",
    "college_chemistry",
    "college_computer_science",
    "college_mathematics",
    "college_medicine"
  ],
  "verbose_mode": false,
  "model_results": [
    {
      "model_name": "Qwen/Qwen2.5-0.5B-Instruct",
      "device": "cpu",
      "quantization_bits": null,
      "overall_accuracy": 9.057706355003653,
      "total_correct": 124,
      "total_questions": 1369,
      "timing": {
        "real_time": 1216.7880973815918,
        "cpu_time": 9409.57,
        "user_time": 9394.17,
        "system_time": 15.4,
        "gpu_time": 0
      },
      "subject_results": [
        {
          "subject": "abstract_algebra",
          "correct": 3,
          "total": 100,
          "accuracy": 3.0,
          "timing": {
            "real_time": 95.05164742469788,
            "cpu_time": 743.82,
            "user_time": 741.21,
            "system_time": 2.6100000000000003,
            "gpu_time": 0
          }
        },
        {
          "subject": "anatomy",
          "correct": 12,
          "total": 135,
          "accuracy": 8.88888888888889,
          "timing": {
            "real_time": 90.9005036354065,
            "cpu_time": 726.51,
            "user_time": 724.37,
            "system_time": 2.1399999999999997,
            "gpu_time": 0
          }
        },
        {
          "subject": "astronomy",
          "correct": 14,
          "total": 152,
          "accuracy": 9.210526315789473,
          "timing": {
            "real_time": 117.54426407814026,
            "cpu_time": 936.27,
            "user_time": 933.96,
            "system_time": 2.3100000000000005,
            "gpu_time": 0
          }
        },
        {
          "subject": "business_ethics",
          "correct": 8,
          "total": 100,
          "accuracy": 8.0,
          "timing": {
            "real_time": 74.2424829006195,
            "cpu_time": 592.2599999999999,
            "user_time": 591.4299999999998,
            "system_time": 0.8300000000000001,
            "gpu_time": 0
          }
        },
        {
          "subject": "clinical_knowledge",
          "correct": 24,
          "total": 265,
          "accuracy": 9.056603773584905,
          "timing": {
            "real_time": 219.858140707016,
            "cpu_time": 1733.6500000000003,
            "user_time": 1732.1000000000004,
            "system_time": 1.5500000000000007,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_biology",
          "correct": 12,
          "total": 144,
          "accuracy": 8.333333333333332,
          "timing": {
            "real_time": 120.95705389976501,
            "cpu_time": 953.6099999999998,
            "user_time": 952.7799999999997,
            "system_time": 0.8300000000000001,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_chemistry",
          "correct": 11,
          "total": 100,
          "accuracy": 11.0,
          "timing": {
            "real_time": 85.98762536048889,
            "cpu_time": 679.6100000000005,
            "user_time": 678.9800000000005,
            "system_time": 0.6300000000000008,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_computer_science",
          "correct": 14,
          "total": 100,
          "accuracy": 14.000000000000002,
          "timing": {
            "real_time": 104.1581461429596,
            "cpu_time": 816.2099999999995,
            "user_time": 815.5599999999995,
            "system_time": 0.6500000000000004,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_mathematics",
          "correct": 5,
          "total": 100,
          "accuracy": 5.0,
          "timing": {
            "real_time": 78.2895119190216,
            "cpu_time": 626.0199999999996,
            "user_time": 625.4399999999996,
            "system_time": 0.5800000000000001,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_medicine",
          "correct": 21,
          "total": 173,
          "accuracy": 12.138728323699421,
          "timing": {
            "real_time": 216.35066509246826,
            "cpu_time": 1601.610000000001,
            "user_time": 1598.340000000001,
            "system_time": 3.269999999999998,
            "gpu_time": 0
          }
        }
      ]
    },
    {
      "model_name": "Qwen/Qwen2.5-1.5B-Instruct",
      "device": "cpu",
      "quantization_bits": null,
      "overall_accuracy": 45.79985390796202,
      "total_correct": 627,
      "total_questions": 1369,
      "timing": {
        "real_time": 4022.144583463669,
        "cpu_time": 31396.270000000004,
        "user_time": 31372.410000000003,
        "system_time": 23.860000000000003,
        "gpu_time": 0
      },
      "subject_results": [
        {
          "subject": "abstract_algebra",
          "correct": 12,
          "total": 100,
          "accuracy": 12.0,
          "timing": {
            "real_time": 264.70591592788696,
            "cpu_time": 2062.4100000000003,
            "user_time": 2057.09,
            "system_time": 5.320000000000004,
            "gpu_time": 0
          }
        },
        {
          "subject": "anatomy",
          "correct": 58,
          "total": 135,
          "accuracy": 42.96296296296296,
          "timing": {
            "real_time": 338.9658353328705,
            "cpu_time": 2655.1800000000017,
            "user_time": 2653.9000000000015,
            "system_time": 1.2800000000000011,
            "gpu_time": 0
          }
        },
        {
          "subject": "astronomy",
          "correct": 90,
          "total": 152,
          "accuracy": 59.210526315789465,
          "timing": {
            "real_time": 435.3745357990265,
            "cpu_time": 3385.219999999998,
            "user_time": 3383.749999999998,
            "system_time": 1.4699999999999989,
            "gpu_time": 0
          }
        },
        {
          "subject": "business_ethics",
          "correct": 63,
          "total": 100,
          "accuracy": 63.0,
          "timing": {
            "real_time": 294.0703561306,
            "cpu_time": 2271.5,
            "user_time": 2270.34,
            "system_time": 1.1600000000000037,
            "gpu_time": 0
          }
        },
        {
          "subject": "clinical_knowledge",
          "correct": 139,
          "total": 265,
          "accuracy": 52.45283018867924,
          "timing": {
            "real_time": 650.3762748241425,
            "cpu_time": 5100.090000000001,
            "user_time": 5097.450000000001,
            "system_time": 2.6400000000000006,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_biology",
          "correct": 78,
          "total": 144,
          "accuracy": 54.166666666666664,
          "timing": {
            "real_time": 428.22663617134094,
            "cpu_time": 3320.489999999999,
            "user_time": 3319.029999999999,
            "system_time": 1.4600000000000009,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_chemistry",
          "correct": 34,
          "total": 100,
          "accuracy": 34.0,
          "timing": {
            "real_time": 308.2217478752136,
            "cpu_time": 2404.5199999999977,
            "user_time": 2403.5599999999977,
            "system_time": 0.9600000000000009,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_computer_science",
          "correct": 39,
          "total": 100,
          "accuracy": 39.0,
          "timing": {
            "real_time": 395.3623025417328,
            "cpu_time": 3033.2199999999975,
            "user_time": 3032.0599999999977,
            "system_time": 1.1599999999999966,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_mathematics",
          "correct": 25,
          "total": 100,
          "accuracy": 25.0,
          "timing": {
            "real_time": 293.031977891922,
            "cpu_time": 2327.0500000000056,
            "user_time": 2326.100000000006,
            "system_time": 0.9499999999999957,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_medicine",
          "correct": 89,
          "total": 173,
          "accuracy": 51.445086705202314,
          "timing": {
            "real_time": 606.4746570587158,
            "cpu_time": 4836.590000000005,
            "user_time": 4829.130000000005,
            "system_time": 7.460000000000001,
            "gpu_time": 0
          }
        }
      ]
    },
    {
      "model_name": "Qwen/Qwen2.5-3B-Instruct",
      "device": "cpu",
      "quantization_bits": null,
      "overall_accuracy": 62.381300219138055,
      "total_correct": 854,
      "total_questions": 1369,
      "timing": {
        "real_time": 8710.562157154083,
        "cpu_time": 69201.34,
        "user_time": 69173.59999999999,
        "system_time": 27.740000000000023,
        "gpu_time": 0
      },
      "subject_results": [
        {
          "subject": "abstract_algebra",
          "correct": 46,
          "total": 100,
          "accuracy": 46.0,
          "timing": {
            "real_time": 582.0720601081848,
            "cpu_time": 4580.529999999999,
            "user_time": 4572.5999999999985,
            "system_time": 7.930000000000007,
            "gpu_time": 0
          }
        },
        {
          "subject": "anatomy",
          "correct": 87,
          "total": 135,
          "accuracy": 64.44444444444444,
          "timing": {
            "real_time": 742.8356664180756,
            "cpu_time": 5901.249999999999,
            "user_time": 5899.029999999999,
            "system_time": 2.219999999999999,
            "gpu_time": 0
          }
        },
        {
          "subject": "astronomy",
          "correct": 109,
          "total": 152,
          "accuracy": 71.71052631578947,
          "timing": {
            "real_time": 927.0609986782074,
            "cpu_time": 7397.979999999993,
            "user_time": 7395.429999999993,
            "system_time": 2.5500000000000114,
            "gpu_time": 0
          }
        },
        {
          "subject": "business_ethics",
          "correct": 75,
          "total": 100,
          "accuracy": 75.0,
          "timing": {
            "real_time": 622.4931302070618,
            "cpu_time": 4937.729999999997,
            "user_time": 4936.3399999999965,
            "system_time": 1.3899999999999864,
            "gpu_time": 0
          }
        },
        {
          "subject": "clinical_knowledge",
          "correct": 186,
          "total": 265,
          "accuracy": 70.18867924528301,
          "timing": {
            "real_time": 1415.3287770748138,
            "cpu_time": 11293.519999999999,
            "user_time": 11289.849999999999,
            "system_time": 3.6700000000000017,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_biology",
          "correct": 103,
          "total": 144,
          "accuracy": 71.52777777777779,
          "timing": {
            "real_time": 910.6044206619263,
            "cpu_time": 7245.770000000003,
            "user_time": 7243.6600000000035,
            "system_time": 2.1099999999999994,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_chemistry",
          "correct": 46,
          "total": 100,
          "accuracy": 46.0,
          "timing": {
            "real_time": 658.1323249340057,
            "cpu_time": 5251.610000000004,
            "user_time": 5249.880000000005,
            "system_time": 1.730000000000004,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_computer_science",
          "correct": 55,
          "total": 100,
          "accuracy": 55.00000000000001,
          "timing": {
            "real_time": 813.8892042636871,
            "cpu_time": 6452.55,
            "user_time": 6450.860000000001,
            "system_time": 1.6899999999999977,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_mathematics",
          "correct": 35,
          "total": 100,
          "accuracy": 35.0,
          "timing": {
            "real_time": 658.892196893692,
            "cpu_time": 5258.479999999993,
            "user_time": 5257.039999999994,
            "system_time": 1.440000000000012,
            "gpu_time": 0
          }
        },
        {
          "subject": "college_medicine",
          "correct": 112,
          "total": 173,
          "accuracy": 64.73988439306359,
          "timing": {
            "real_time": 1371.3118090629578,
            "cpu_time": 10881.920000000004,
            "user_time": 10878.910000000003,
            "system_time": 3.010000000000005,
            "gpu_time": 0
          }
        }
      ]
    }
  ]
}