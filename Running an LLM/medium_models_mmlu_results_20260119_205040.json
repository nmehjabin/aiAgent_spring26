{
  "timestamp": "20260119_205040",
  "device": "cuda",
  "num_subjects": 10,
  "subjects": [
    "abstract_algebra",
    "anatomy",
    "astronomy",
    "business_ethics",
    "clinical_knowledge",
    "college_biology",
    "college_chemistry",
    "college_computer_science",
    "college_mathematics",
    "college_medicine"
  ],
  "verbose_mode": false,
  "model_results": [
    {
      "model_name": "Qwen/Qwen2.5-7B-Instruct",
      "device": "cuda",
      "quantization_bits": 4,
      "overall_accuracy": 59.97078159240321,
      "total_correct": 821,
      "total_questions": 1369,
      "timing": {
        "real_time": 337.33281564712524,
        "cpu_time": 323.24000000000007,
        "user_time": 307.02,
        "system_time": 16.22,
        "gpu_time": 328.0308816432953
      },
      "subject_results": [
        {
          "subject": "abstract_algebra",
          "correct": 35,
          "total": 100,
          "accuracy": 35.0,
          "timing": {
            "real_time": 23.33132576942444,
            "cpu_time": 22.12,
            "user_time": 21.37,
            "system_time": 0.75,
            "gpu_time": 23.33132576942444
          }
        },
        {
          "subject": "anatomy",
          "correct": 84,
          "total": 135,
          "accuracy": 62.22222222222222,
          "timing": {
            "real_time": 31.834725379943848,
            "cpu_time": 31.47,
            "user_time": 30.049999999999997,
            "system_time": 1.42,
            "gpu_time": 31.834725379943848
          }
        },
        {
          "subject": "astronomy",
          "correct": 114,
          "total": 152,
          "accuracy": 75.0,
          "timing": {
            "real_time": 34.958733320236206,
            "cpu_time": 34.46,
            "user_time": 32.95,
            "system_time": 1.5099999999999998,
            "gpu_time": 34.958733320236206
          }
        },
        {
          "subject": "business_ethics",
          "correct": 72,
          "total": 100,
          "accuracy": 72.0,
          "timing": {
            "real_time": 23.211382389068604,
            "cpu_time": 22.890000000000008,
            "user_time": 21.900000000000006,
            "system_time": 0.990000000000002,
            "gpu_time": 23.211382389068604
          }
        },
        {
          "subject": "clinical_knowledge",
          "correct": 194,
          "total": 265,
          "accuracy": 73.20754716981132,
          "timing": {
            "real_time": 59.69336223602295,
            "cpu_time": 59.08,
            "user_time": 56.56,
            "system_time": 2.5199999999999996,
            "gpu_time": 59.69336223602295
          }
        },
        {
          "subject": "college_biology",
          "correct": 113,
          "total": 144,
          "accuracy": 78.47222222222221,
          "timing": {
            "real_time": 34.104407787323,
            "cpu_time": 33.650000000000006,
            "user_time": 32.03,
            "system_time": 1.620000000000001,
            "gpu_time": 34.104407787323
          }
        },
        {
          "subject": "college_chemistry",
          "correct": 34,
          "total": 100,
          "accuracy": 34.0,
          "timing": {
            "real_time": 24.064358711242676,
            "cpu_time": 23.749999999999996,
            "user_time": 22.659999999999997,
            "system_time": 1.0899999999999999,
            "gpu_time": 24.064358711242676
          }
        },
        {
          "subject": "college_computer_science",
          "correct": 49,
          "total": 100,
          "accuracy": 49.0,
          "timing": {
            "real_time": 26.34779167175293,
            "cpu_time": 26.08,
            "user_time": 24.28,
            "system_time": 1.7999999999999972,
            "gpu_time": 26.34779167175293
          }
        },
        {
          "subject": "college_mathematics",
          "correct": 20,
          "total": 100,
          "accuracy": 20.0,
          "timing": {
            "real_time": 24.17741298675537,
            "cpu_time": 23.919999999999998,
            "user_time": 22.689999999999998,
            "system_time": 1.2300000000000004,
            "gpu_time": 24.17741298675537
          }
        },
        {
          "subject": "college_medicine",
          "correct": 106,
          "total": 173,
          "accuracy": 61.27167630057804,
          "timing": {
            "real_time": 46.30738139152527,
            "cpu_time": 45.81999999999997,
            "user_time": 42.52999999999997,
            "system_time": 3.289999999999999,
            "gpu_time": 46.30738139152527
          }
        }
      ]
    },
    {
      "model_name": "Qwen/Qwen2.5-14B-Instruct",
      "device": "cuda",
      "quantization_bits": 4,
      "overall_accuracy": 73.84952520087656,
      "total_correct": 1011,
      "total_questions": 1369,
      "timing": {
        "real_time": 667.1108753681183,
        "cpu_time": 653.2900000000002,
        "user_time": 542.69,
        "system_time": 110.59999999999998,
        "gpu_time": 659.6371245384216
      },
      "subject_results": [
        {
          "subject": "abstract_algebra",
          "correct": 55,
          "total": 100,
          "accuracy": 55.00000000000001,
          "timing": {
            "real_time": 42.051655530929565,
            "cpu_time": 41.54000000000003,
            "user_time": 35.72000000000003,
            "system_time": 5.82,
            "gpu_time": 42.051655530929565
          }
        },
        {
          "subject": "anatomy",
          "correct": 99,
          "total": 135,
          "accuracy": 73.33333333333333,
          "timing": {
            "real_time": 58.27629470825195,
            "cpu_time": 57.659999999999954,
            "user_time": 49.35999999999996,
            "system_time": 8.299999999999997,
            "gpu_time": 58.27629470825195
          }
        },
        {
          "subject": "astronomy",
          "correct": 135,
          "total": 152,
          "accuracy": 88.81578947368422,
          "timing": {
            "real_time": 70.94735980033875,
            "cpu_time": 70.34,
            "user_time": 58.56,
            "system_time": 11.780000000000001,
            "gpu_time": 70.94735980033875
          }
        },
        {
          "subject": "business_ethics",
          "correct": 77,
          "total": 100,
          "accuracy": 77.0,
          "timing": {
            "real_time": 47.8971529006958,
            "cpu_time": 47.39999999999999,
            "user_time": 39.56999999999999,
            "system_time": 7.829999999999998,
            "gpu_time": 47.8971529006958
          }
        },
        {
          "subject": "clinical_knowledge",
          "correct": 217,
          "total": 265,
          "accuracy": 81.88679245283019,
          "timing": {
            "real_time": 122.14758920669556,
            "cpu_time": 121.11999999999995,
            "user_time": 101.42999999999995,
            "system_time": 19.689999999999998,
            "gpu_time": 122.14758920669556
          }
        },
        {
          "subject": "college_biology",
          "correct": 125,
          "total": 144,
          "accuracy": 86.80555555555556,
          "timing": {
            "real_time": 70.02285289764404,
            "cpu_time": 69.2600000000001,
            "user_time": 57.510000000000105,
            "system_time": 11.75,
            "gpu_time": 70.02285289764404
          }
        },
        {
          "subject": "college_chemistry",
          "correct": 50,
          "total": 100,
          "accuracy": 50.0,
          "timing": {
            "real_time": 49.374619245529175,
            "cpu_time": 48.89000000000003,
            "user_time": 40.34000000000003,
            "system_time": 8.549999999999997,
            "gpu_time": 49.374619245529175
          }
        },
        {
          "subject": "college_computer_science",
          "correct": 63,
          "total": 100,
          "accuracy": 63.0,
          "timing": {
            "real_time": 54.05683207511902,
            "cpu_time": 53.56999999999999,
            "user_time": 43.379999999999995,
            "system_time": 10.189999999999998,
            "gpu_time": 54.05683207511902
          }
        },
        {
          "subject": "college_mathematics",
          "correct": 54,
          "total": 100,
          "accuracy": 54.0,
          "timing": {
            "real_time": 49.677557945251465,
            "cpu_time": 49.22,
            "user_time": 40.629999999999995,
            "system_time": 8.590000000000003,
            "gpu_time": 49.677557945251465
          }
        },
        {
          "subject": "college_medicine",
          "correct": 136,
          "total": 173,
          "accuracy": 78.61271676300578,
          "timing": {
            "real_time": 95.18521022796631,
            "cpu_time": 94.29000000000005,
            "user_time": 76.19000000000005,
            "system_time": 18.099999999999994,
            "gpu_time": 95.18521022796631
          }
        }
      ]
    }
  ]
}