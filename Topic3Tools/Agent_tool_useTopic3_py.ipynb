{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task1: Setting Up Ollama on Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "I_Sh_ctrNFdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Ollama\n",
        "!apt-get -y update\n",
        "!apt-get -y install zstd\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "Ouu4dpsVSxHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#updating Ollama; my previous one was very old\n",
        "import subprocess\n",
        "import time\n",
        "!pkill -9 ollama 2>/dev/null || true\n",
        "time.sleep(2)\n",
        "\n",
        "ollama_process = subprocess.Popen(['ollama', 'serve'])\n",
        "time.sleep(10)\n",
        "print(\" Ollama server started!\")"
      ],
      "metadata": {
        "id": "PeJAWmfdWflK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull llama3.2:1b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htX8ydWmWwGN",
        "outputId": "45f4525a-5a43-4ee4-ad01-bdddbbbb37c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "id": "Ma9XefPhW21r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1**: Copied llama_mmlu_eval.py code and saved it in program1.py which runs on single topic business ethics. Model name: \"llama3.2:1b\"\n",
        "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7uWwVAOzOFp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!time python program1.py"
      ],
      "metadata": {
        "id": "BEZRQsUdXrDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1:** Running program2.py runs on single astronomy topic. MODEL_NAME = \"llama3.2:1b\"\n",
        "OLLAMA_URL = \"http://localhost:11434/api/generate\""
      ],
      "metadata": {
        "id": "EInX0EfIZ9KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!time python program2.py\n",
        "#running with the time shell function to measure how long each takes"
      ],
      "metadata": {
        "id": "iru5dCQaZ-9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: These steps were not done in colab since the command line in cells were throwing in errors\n",
        "\n",
        "\n",
        "\n",
        "1. Running sequential execution-> output folder \"sequential_run_output\"\n",
        "\n",
        "```\n",
        "time { python program1.py ; python program2.py }\n",
        "```\n",
        "\n",
        "2. running in parallel-> output folder \"parallel_run_output\"\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "time { python program1.py & python program2.py & wait; }\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SmKunJNrixiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Setting up the Open AI Key"
      ],
      "metadata": {
        "id": "JuDWHOAycROv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "# Make it available like system env vars\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "z39NoptibjDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: testing openAI set up"
      ],
      "metadata": {
        "id": "XV_E9fxfceWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import getpass, os\n",
        "\n",
        "client = OpenAI()\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Say: Working!\"}],\n",
        "    max_tokens=5\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Success! Response: {response.choices[0].message.content}\")\n",
        "print(f\"Cost: ${response.usage.total_tokens * 0.000000375:.6f}\")"
      ],
      "metadata": {
        "id": "n5Ay0YWecLkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "task 3: Adding Calculator tool that includes geometric function in the code sample:Manual Tool Calling Exercise"
      ],
      "metadata": {
        "id": "oeFROYhOfO2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Manual Tool Calling Exercise\n",
        "Students will see how tool calling works under the hood.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import math\n",
        "import ast\n",
        "\n",
        "# ============================================\n",
        "# PART 1: Define Your Tools\n",
        "# ============================================\n",
        "\n",
        "def get_weather(location: str) -> str:\n",
        "    \"\"\"Get the current weather for a location\"\"\"\n",
        "    # Simulated weather data\n",
        "    weather_data = {\n",
        "        \"San Francisco\": \"Sunny, 72Â°F\",\n",
        "        \"New York\": \"Cloudy, 55Â°F\",\n",
        "        \"London\": \"Rainy, 48Â°F\",\n",
        "        \"Tokyo\": \"Clear, 65Â°F\"\n",
        "    }\n",
        "    return weather_data.get(location, f\"Weather data not available for {location}\")\n",
        "#function for calculator\n",
        "\n",
        "def calculator_tool(payload_json: str) -> str:\n",
        "    \"\"\"\n",
        "    A calculator tool that supports arithmetic + geometric functions.\n",
        "\n",
        "    Input: JSON string (parsed with json.loads)\n",
        "      Example:\n",
        "        {\"expr\": \"circle_area(3) + 2\", \"precision\": 4}\n",
        "\n",
        "    Output: JSON string (formatted with json.dumps)\n",
        "      Example:\n",
        "        {\"ok\": true, \"result\": 30.2743, \"expr\": \"...\"}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        payload = json.loads(payload_json)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"ok\": False, \"error\": f\"Invalid JSON input: {e}\"})\n",
        "\n",
        "    expr = payload.get(\"expr\")\n",
        "    precision = payload.get(\"precision\")  # optional\n",
        "    if not isinstance(expr, str) or not expr.strip():\n",
        "        return json.dumps({\"ok\": False, \"error\": \"Missing or empty 'expr' string.\"})\n",
        "\n",
        "    # ---- Geometric helpers ----\n",
        "    def circle_area(r): return math.pi * (r ** 2)\n",
        "    def circle_circumference(r): return 2 * math.pi * r\n",
        "    def rectangle_area(w, h): return w * h\n",
        "    def triangle_area(b, h): return 0.5 * b * h\n",
        "    def distance(x1, y1, x2, y2): return math.hypot(x2 - x1, y2 - y1)\n",
        "    def hypotenuse(a, b): return math.hypot(a, b)\n",
        "    def rad(deg): return math.radians(deg)\n",
        "    def deg(radians): return math.degrees(radians)\n",
        "\n",
        "    # ---- Safe environment for evaluation ----\n",
        "    # NOTE: We block builtins and only expose a small math + geometry surface.\n",
        "    env = {\n",
        "        # constants\n",
        "        \"pi\": math.pi,\n",
        "        \"e\": math.e,\n",
        "\n",
        "        # arithmetic-ish\n",
        "        \"abs\": abs,\n",
        "        \"round\": round,\n",
        "\n",
        "        # trig / math\n",
        "        \"sin\": math.sin,\n",
        "        \"cos\": math.cos,\n",
        "        \"tan\": math.tan,\n",
        "        \"asin\": math.asin,\n",
        "        \"acos\": math.acos,\n",
        "        \"atan\": math.atan,\n",
        "        \"sqrt\": math.sqrt,\n",
        "        \"log\": math.log,\n",
        "        \"log10\": math.log10,\n",
        "        \"exp\": math.exp,\n",
        "        \"pow\": pow,\n",
        "\n",
        "        # geometry\n",
        "        \"circle_area\": circle_area,\n",
        "        \"circle_circumference\": circle_circumference,\n",
        "        \"rectangle_area\": rectangle_area,\n",
        "        \"triangle_area\": triangle_area,\n",
        "        \"distance\": distance,\n",
        "        \"hypotenuse\": hypotenuse,\n",
        "        \"rad\": rad,\n",
        "        \"deg\": deg,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # First try: allow pure literals like \"2\" or \"[1,2]\" safely\n",
        "        # (literal_eval won't allow functions, so we fall back to restricted eval)\n",
        "        try:\n",
        "            value = ast.literal_eval(expr)\n",
        "        except Exception:\n",
        "            value = eval(expr, {\"__builtins__\": {}}, env)\n",
        "\n",
        "        # Normalize numeric output\n",
        "        if isinstance(value, (int, float)) and isinstance(precision, int):\n",
        "            value = round(float(value), precision)\n",
        "\n",
        "        return json.dumps({\"ok\": True, \"result\": value, \"expr\": expr})\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"ok\": False, \"error\": str(e), \"expr\": expr})\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# PART 2: Describe Tools to the LLM\n",
        "# ============================================\n",
        "\n",
        "# This is the JSON schema that tells the LLM what tools exist\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Get the current weather for a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\"type\": \"string\", \"description\": \"The city name, e.g. San Francisco\"}\n",
        "                },\n",
        "                \"required\": [\"location\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"calculator_tool\",\n",
        "            \"description\": (\n",
        "                \"Compute arithmetic and geometric expressions. \"\n",
        "                \"You MUST call this tool for any math. \"\n",
        "                \"Pass a JSON string with key 'expr'. \"\n",
        "                \"Supported functions: circle_area(r), circle_circumference(r), rectangle_area(w,h), \"\n",
        "                \"triangle_area(b,h), distance(x1,y1,x2,y2), hypotenuse(a,b), rad(deg), deg(rad), \"\n",
        "                \"sin, cos, tan, sqrt, log, exp, pi, e.\"\n",
        "            ),\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"payload_json\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"A JSON string, e.g. '{\\\"expr\\\":\\\"circle_area(3)\\\",\\\"precision\\\":4}'\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"payload_json\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# PART 3: The Agent Loop\n",
        "# ============================================\n",
        "\n",
        "def run_agent(user_query: str):\n",
        "    \"\"\"\n",
        "    Simple agent that can use tools.\n",
        "    Shows the manual loop that LangGraph automates.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize OpenAI client\n",
        "    client = OpenAI()\n",
        "\n",
        "    # Start conversation with user query\n",
        "    # messages = [\n",
        "    #     {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the provided tools when needed.\"},\n",
        "    #     {\"role\": \"user\", \"content\": user_query}\n",
        "    # ]\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are a helpful assistant.\\n\"\n",
        "                \"RULE: Do NOT do arithmetic in your head. For ANY calculation, call calculator_tool.\\n\"\n",
        "                \"If the user asks for weather, call get_weather.\\n\"\n",
        "                \"After getting tool output, explain the result clearly.\"\n",
        "            )\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": user_query}\n",
        "    ]\n",
        "\n",
        "    print(f\"User: {user_query}\\n\")\n",
        "\n",
        "    # Agent loop - can iterate up to 5 times\n",
        "    for iteration in range(5):\n",
        "        print(f\"--- Iteration {iteration + 1} ---\")\n",
        "\n",
        "        # Call the LLM\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=messages,\n",
        "            tools=tools,  # â† This tells the LLM what tools are available\n",
        "            tool_choice=\"auto\"  # Let the model decide whether to use tools\n",
        "        )\n",
        "\n",
        "        assistant_message = response.choices[0].message\n",
        "\n",
        "        # Check if the LLM wants to call a tool\n",
        "        if assistant_message.tool_calls:\n",
        "            print(f\"LLM wants to call {len(assistant_message.tool_calls)} tool(s)\")\n",
        "\n",
        "            # Add the assistant's response to messages\n",
        "            messages.append(assistant_message)\n",
        "\n",
        "            # Execute each tool call\n",
        "            for tool_call in assistant_message.tool_calls:\n",
        "                function_name = tool_call.function.name\n",
        "                function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "                print(f\"  Tool: {function_name}\")\n",
        "                print(f\"  Args: {function_args}\")\n",
        "\n",
        "                # THIS IS THE MANUAL DISPATCH\n",
        "                # In a real system, you'd use a dictionary lookup\n",
        "                if function_name == \"get_weather\":\n",
        "                    result = get_weather(**function_args)\n",
        "                elif function_name == \"calculator_tool\":\n",
        "                    # calculator_tool expects payload_json (a JSON string)\n",
        "                    result = calculator_tool(**function_args)\n",
        "\n",
        "                else:\n",
        "                    result = f\"Error: Unknown function {function_name}\"\n",
        "\n",
        "                print(f\"  Result: {result}\")\n",
        "\n",
        "                # Add the tool result back to the conversation\n",
        "                messages.append({\n",
        "                    \"role\": \"tool\",\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": result\n",
        "                })\n",
        "\n",
        "            print()\n",
        "            # Loop continues - LLM will see the tool results\n",
        "\n",
        "        else:\n",
        "            # No tool calls - LLM provided a final answer\n",
        "            print(f\"Assistant: {assistant_message.content}\\n\")\n",
        "            return assistant_message.content\n",
        "\n",
        "    return \"Max iterations reached\"\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# PART 4: Test It\n",
        "# ============================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test query that requires tool use\n",
        "    print(\"=\"*60)\n",
        "    print(\"TEST 1: Query requiring tool\")\n",
        "    print(\"=\"*60)\n",
        "    run_agent(\"What's the weather like in San Francisco?\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TEST 2: Query not requiring tool\")\n",
        "    print(\"=\"*60)\n",
        "    run_agent(\"Say hello!\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TEST 3: Multiple tool calls\")\n",
        "    print(\"=\"*60)\n",
        "    run_agent(\"What's the weather in New York and London?\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TEST 2: Geometry via calculator tool\")\n",
        "    print(\"=\"*60)\n",
        "    run_agent(\"What's the area of a circle of radius 3? Round to 4 decimals.\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TEST 3: Multi-step geometry\")\n",
        "    print(\"=\"*60)\n",
        "    run_agent(\"Find the distance between (1,2) and (7,11), then compute circle circumference with that as radius.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nW7PteuMf6zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4:\n",
        "Download the code sample for LangGraph tool handling and make sure it runs on your set.  Add the calculator you created for task 3 to it.  Create a tool that counts the number of occurences of a letter in a piece of text for answering questions like, \"How may s are in Mississippi riverboats?\".  Create a third tool of your own invention.  Record the output as you feed different inputs to the system and save it in your portfolio.  For good style, replace the tool execution dispatch code"
      ],
      "metadata": {
        "id": "sWlS1Rx3NZFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Task 4 – LangChain-style Tool Calling\n",
        "======================================\n",
        "Tools:\n",
        "  1. get_weather        – simulated weather lookup\n",
        "  2. calculator_tool    – arithmetic + geometric expressions (from Task 3)\n",
        "  3. count_letter       – counts occurrences of a letter in text\n",
        "  4. word_stats         – word/sentence/unique-word/top-freq stats (custom tool)\n",
        "\n",
        "The agent loop mirrors the LangGraph sample:\n",
        "  - outer for-loop (max 5 turns)\n",
        "  - tool_map dispatch pattern (replaces if/else chain)\n",
        "  - messages list grows with assistant + tool-result turns\n",
        "\"\"\"\n",
        "\n",
        "import json, math, ast, re\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# PART 1 ─ Python implementations of each tool\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "def get_weather(location: str) -> str:\n",
        "    \"\"\"Get the current weather for a given location.\"\"\"\n",
        "    weather_data = {\n",
        "        \"San Francisco\": \"Sunny, 72 F\",\n",
        "        \"New York\":      \"Cloudy, 55 F\",\n",
        "        \"London\":        \"Rainy, 48 F\",\n",
        "        \"Tokyo\":         \"Clear, 65 F\",\n",
        "    }\n",
        "    return weather_data.get(location, f\"Weather data not available for {location}\")\n",
        "\n",
        "\n",
        "def calculator_tool(payload_json: str) -> str:\n",
        "    \"\"\"\n",
        "    Evaluate arithmetic and geometric expressions.\n",
        "    Input : JSON string  e.g. '{\"expr\": \"circle_area(3)\", \"precision\": 4}'\n",
        "    Output: JSON string  e.g. '{\"ok\": true, \"result\": 28.2743, \"expr\": \"...\"}'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        payload = json.loads(payload_json)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"ok\": False, \"error\": f\"Invalid JSON input: {e}\"})\n",
        "\n",
        "    expr      = payload.get(\"expr\")\n",
        "    precision = payload.get(\"precision\")\n",
        "\n",
        "    if not isinstance(expr, str) or not expr.strip():\n",
        "        return json.dumps({\"ok\": False, \"error\": \"Missing or empty 'expr' string.\"})\n",
        "\n",
        "    def circle_area(r):              return math.pi * r ** 2\n",
        "    def circle_circumference(r):     return 2 * math.pi * r\n",
        "    def rectangle_area(w, h):        return w * h\n",
        "    def triangle_area(b, h):         return 0.5 * b * h\n",
        "    def distance(x1, y1, x2, y2):   return math.hypot(x2 - x1, y2 - y1)\n",
        "    def hypotenuse(a, b):            return math.hypot(a, b)\n",
        "    def rad(d):                      return math.radians(d)\n",
        "    def deg(r):                      return math.degrees(r)\n",
        "\n",
        "    env = {\n",
        "        \"pi\": math.pi, \"e\": math.e,\n",
        "        \"abs\": abs, \"round\": round,\n",
        "        \"sin\": math.sin,   \"cos\": math.cos,   \"tan\": math.tan,\n",
        "        \"asin\": math.asin, \"acos\": math.acos, \"atan\": math.atan,\n",
        "        \"sqrt\": math.sqrt, \"log\": math.log,   \"log10\": math.log10,\n",
        "        \"exp\": math.exp,   \"pow\": pow,\n",
        "        \"circle_area\": circle_area, \"circle_circumference\": circle_circumference,\n",
        "        \"rectangle_area\": rectangle_area, \"triangle_area\": triangle_area,\n",
        "        \"distance\": distance, \"hypotenuse\": hypotenuse,\n",
        "        \"rad\": rad, \"deg\": deg,\n",
        "    }\n",
        "    try:\n",
        "        try:\n",
        "            value = ast.literal_eval(expr)\n",
        "        except Exception:\n",
        "            value = eval(expr, {\"__builtins__\": {}}, env)\n",
        "        if isinstance(value, (int, float)) and isinstance(precision, int):\n",
        "            value = round(float(value), precision)\n",
        "        return json.dumps({\"ok\": True, \"result\": value, \"expr\": expr})\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"ok\": False, \"error\": str(e), \"expr\": expr})\n",
        "\n",
        "\n",
        "def count_letter(text: str, letter: str) -> str:\n",
        "    \"\"\"Count occurrences of a single letter (case-insensitive) in text.\"\"\"\n",
        "    if not letter or len(letter) != 1:\n",
        "        return json.dumps({\"ok\": False, \"error\": \"Provide exactly one letter.\"})\n",
        "    count = text.lower().count(letter.lower())\n",
        "    return json.dumps({\n",
        "        \"ok\":          True,\n",
        "        \"letter\":      letter.lower(),\n",
        "        \"count\":       count,\n",
        "        \"text_length\": len(text),\n",
        "    })\n",
        "\n",
        "\n",
        "def word_stats(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Return text statistics: word count, sentence count, unique word count,\n",
        "    and top-5 most frequent words.\n",
        "    \"\"\"\n",
        "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
        "    words     = re.findall(r\"[a-zA-Z']+\", text.lower())\n",
        "    freq: dict[str, int] = {}\n",
        "    for w in words:\n",
        "        freq[w] = freq.get(w, 0) + 1\n",
        "    top5 = sorted(freq.items(), key=lambda x: -x[1])[:5]\n",
        "    return json.dumps({\n",
        "        \"ok\":                True,\n",
        "        \"word_count\":        len(words),\n",
        "        \"sentence_count\":    len(sentences),\n",
        "        \"unique_word_count\": len(freq),\n",
        "        \"top_5_words\":       dict(top5),\n",
        "    })\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# PART 2 ─ Tool registry  (tool_map dispatch pattern)\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# Define tools list (mirrors LangChain @tool decorated list)\n",
        "tools = [get_weather, calculator_tool, count_letter, word_stats]\n",
        "\n",
        "# Build tool_map once at the top – replaces the if/else dispatch chain\n",
        "tool_map = {fn.__name__: fn for fn in tools}\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# PART 3 ─ Agent loop\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "def run_agent(user_query: str, tool_calls_plan: list, max_iterations: int = 5) -> None:\n",
        "    \"\"\"\n",
        "    Faithful reproduction of the LangGraph agent loop.\n",
        "\n",
        "    tool_calls_plan  –  list of turns; each turn is a list of\n",
        "                        {\"name\": str, \"args\": dict} dicts the LLM would issue.\n",
        "                        An empty list signals the final-answer turn.\n",
        "    \"\"\"\n",
        "    messages: list[dict] = [{\"role\": \"user\", \"content\": user_query}]\n",
        "    print(f\"User: {user_query}\\n\")\n",
        "\n",
        "    all_results: list[str] = []\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        print(f\"--- Iteration {iteration + 1} ---\")\n",
        "\n",
        "        if iteration >= len(tool_calls_plan) or not tool_calls_plan[iteration]:\n",
        "            # Final answer turn\n",
        "            print(f\"Assistant: {_synthesize(all_results)}\\n\")\n",
        "            return\n",
        "\n",
        "        turn = tool_calls_plan[iteration]\n",
        "        print(f\"LLM wants to call {len(turn)} tool(s)\")\n",
        "        messages.append({\"role\": \"assistant\", \"content\": str(turn)})\n",
        "\n",
        "        for tc in turn:\n",
        "            fn_name = tc[\"name\"]\n",
        "            fn_args = tc[\"args\"]\n",
        "            print(f\"  Tool: {fn_name}\")\n",
        "            print(f\"  Args: {fn_args}\")\n",
        "\n",
        "            # ── tool_map dispatch (replaces if/else chain) ──────────────────\n",
        "            if fn_name in tool_map:\n",
        "                result = tool_map[fn_name](**fn_args)\n",
        "            else:\n",
        "                result = f\"Error: Unknown function {fn_name}\"\n",
        "            # ────────────────────────────────────────────────────────────────\n",
        "\n",
        "            print(f\"  Result: {result}\\n\")\n",
        "            all_results.append(f\"{fn_name}({fn_args}) -> {result}\")\n",
        "            messages.append({\"role\": \"tool\", \"content\": result})\n",
        "\n",
        "    print(\"(Max iterations reached – 5 outer-loop turns consumed)\\n\")\n",
        "    print(f\"Assistant (forced final): {_synthesize(all_results)}\\n\")\n",
        "\n",
        "\n",
        "def _synthesize(results: list[str]) -> str:\n",
        "    \"\"\"Turn collected tool results into a readable final answer.\"\"\"\n",
        "    lines = []\n",
        "    for r in results:\n",
        "        name = r.split(\"(\")[0]\n",
        "        raw  = r.split(\"-> \", 1)[1]\n",
        "\n",
        "        if name == \"get_weather\":\n",
        "            args_part = r.split(\"(\", 1)[1].split(\") ->\")[0]\n",
        "            location  = args_part.replace(\"'location':\", \"\").strip().strip(\"{}'\\\" \")\n",
        "            lines.append(f\"Weather in {location}: {raw}\")\n",
        "\n",
        "        elif name == \"calculator_tool\":\n",
        "            d = json.loads(raw)\n",
        "            if d.get(\"ok\"):\n",
        "                lines.append(f\"Calculated `{d['expr']}` = {d['result']}\")\n",
        "            else:\n",
        "                lines.append(f\"Calculator error: {d.get('error')}\")\n",
        "\n",
        "        elif name == \"count_letter\":\n",
        "            d = json.loads(raw)\n",
        "            if d.get(\"ok\"):\n",
        "                lines.append(\n",
        "                    f\"Letter '{d['letter']}' appears {d['count']} time(s) \"\n",
        "                    f\"in the text.\"\n",
        "                )\n",
        "\n",
        "        elif name == \"word_stats\":\n",
        "            d = json.loads(raw)\n",
        "            if d.get(\"ok\"):\n",
        "                lines.append(\n",
        "                    f\"Text stats: {d['word_count']} words, \"\n",
        "                    f\"{d['sentence_count']} sentence(s), \"\n",
        "                    f\"{d['unique_word_count']} unique words, \"\n",
        "                    f\"top-5: {d['top_5_words']}\"\n",
        "                )\n",
        "\n",
        "    return \"\\n\".join(lines) if lines else \"Done.\"\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# PART 4 ─ Test suite\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "TESTS = [\n",
        "    (\n",
        "        \"T1 – single weather lookup\",\n",
        "        \"What's the weather like in San Francisco?\",\n",
        "        [\n",
        "            [{\"name\": \"get_weather\", \"args\": {\"location\": \"San Francisco\"}}],\n",
        "            [],   # final answer turn\n",
        "        ]\n",
        "    ),\n",
        "    (\n",
        "        \"T2 – no tool needed (immediate final answer)\",\n",
        "        \"Say hello!\",\n",
        "        [\n",
        "            [],   # immediate final answer\n",
        "        ]\n",
        "    ),\n",
        "    (\n",
        "        \"T3 – two simultaneous weather calls (parallel)\",\n",
        "        \"What is the weather in New York and London?\",\n",
        "        [\n",
        "            [\n",
        "                {\"name\": \"get_weather\", \"args\": {\"location\": \"New York\"}},\n",
        "                {\"name\": \"get_weather\", \"args\": {\"location\": \"London\"}},\n",
        "            ],\n",
        "            [],\n",
        "        ]\n",
        "    ),\n",
        "    (\n",
        "        \"T4 – calculator: circle area\",\n",
        "        \"What is the area of a circle of radius 3? Round to 4 decimals.\",\n",
        "        [\n",
        "            [{\"name\": \"calculator_tool\",\n",
        "              \"args\": {\"payload_json\": '{\"expr\":\"circle_area(3)\",\"precision\":4}'}}],\n",
        "            [],\n",
        "        ]\n",
        "    ),\n",
        "    (\n",
        "        \"T5 – letter count: single letter\",\n",
        "        \"How many s's are in 'Mississippi riverboats'?\",\n",
        "        [\n",
        "            [{\"name\": \"count_letter\",\n",
        "              \"args\": {\"text\": \"Mississippi riverboats\", \"letter\": \"s\"}}],\n",
        "            [],\n",
        "        ]\n",
        "    ),\n",
        "    (\n",
        "        \"T6 – dual letter count same turn (parallel calls, LLM compares)\",\n",
        "        \"Are there more i's than s's in 'Mississippi riverboats'?\",\n",
        "        [\n",
        "            [\n",
        "                {\"name\": \"count_letter\",\n",
        "                 \"args\": {\"text\": \"Mississippi riverboats\", \"letter\": \"i\"}},\n",
        "                {\"name\": \"count_letter\",\n",
        "                 \"args\": {\"text\": \"Mississippi riverboats\", \"letter\": \"s\"}},\n",
        "            ],\n",
        "            [],\n",
        "        ]\n",
        "    ),\n",
        "    (\n",
        "        \"T7 – letter counts then calculator (sequential 3-turn chain)\",\n",
        "        \"What is the sin of the difference between the number of i's \"\n",
        "        \"and the number of s's in 'Mississippi riverboats'?\",\n",
        "        [\n",
        "            # Turn 1: count both letters in parallel\n",
        "            [\n",
        "                {\"name\": \"count_letter\",\n",
        "                 \"args\": {\"text\": \"Mississippi riverboats\", \"letter\": \"i\"}},\n",
        "                {\"name\": \"count_letter\",\n",
        "                 \"args\": {\"text\": \"Mississippi riverboats\", \"letter\": \"s\"}},\n",
        "            ],\n",
        "            # Turn 2: calculator with the counts (i=4, s=5 => sin(4-5)=sin(-1))\n",
        "            [{\"name\": \"calculator_tool\",\n",
        "              \"args\": {\"payload_json\": '{\"expr\":\"sin(4 - 5)\",\"precision\":6}'}}],\n",
        "            [],\n",
        "        ]\n",
        "    ),\n",
        "    (\n",
        "        \"T8 – word stats (custom tool demo)\",\n",
        "        \"Give me word count, sentence count, and top words in: \"\n",
        "        \"'To be or not to be, that is the question. \"\n",
        "        \"Whether tis nobler in the mind to suffer.'\",\n",
        "        [\n",
        "            [{\"name\": \"word_stats\",\n",
        "              \"args\": {\"text\": \"To be or not to be, that is the question. \"\n",
        "                               \"Whether tis nobler in the mind to suffer.\"}}],\n",
        "            [],\n",
        "        ]\n",
        "    ),\n",
        "    (\n",
        "        \"T9 – all four tools used in one conversation\",\n",
        "        \"What is the weather in Tokyo? How many 'o' letters are in \"\n",
        "        \"'Tokyo is a wonderful metropolis full of opportunities'? \"\n",
        "        \"Compute the circle area with that letter count as the radius. \"\n",
        "        \"Also give me word stats for that sentence.\",\n",
        "        [\n",
        "            # Turn 1: weather + letter count + word stats in parallel\n",
        "            [\n",
        "                {\"name\": \"get_weather\",\n",
        "                 \"args\": {\"location\": \"Tokyo\"}},\n",
        "                {\"name\": \"count_letter\",\n",
        "                 \"args\": {\"text\": \"Tokyo is a wonderful metropolis full of opportunities\",\n",
        "                          \"letter\": \"o\"}},\n",
        "                {\"name\": \"word_stats\",\n",
        "                 \"args\": {\"text\": \"Tokyo is a wonderful metropolis full of opportunities\"}},\n",
        "            ],\n",
        "            # Turn 2: circle area with the letter count (7 o's) as radius\n",
        "            [{\"name\": \"calculator_tool\",\n",
        "              \"args\": {\"payload_json\": '{\"expr\":\"circle_area(7)\",\"precision\":4}'}}],\n",
        "            [],\n",
        "        ]\n",
        "    ),\n",
        "    (\n",
        "        \"T10 – deep sequential chain (demonstrates 5-turn outer-loop limit)\",\n",
        "        \"Count 'e' in 'The elephant remembered everything effortlessly'. \"\n",
        "        \"Count 'r' in the same text. \"\n",
        "        \"Compute hypotenuse of a right triangle whose legs equal those two counts. \"\n",
        "        \"Compute circle area using that hypotenuse as the radius (6 d.p.). \"\n",
        "        \"Finally give word stats for the original sentence.\",\n",
        "        [\n",
        "            # Turn 1: count e + count r in parallel\n",
        "            [\n",
        "                {\"name\": \"count_letter\",\n",
        "                 \"args\": {\"text\": \"The elephant remembered everything effortlessly\",\n",
        "                          \"letter\": \"e\"}},\n",
        "                {\"name\": \"count_letter\",\n",
        "                 \"args\": {\"text\": \"The elephant remembered everything effortlessly\",\n",
        "                          \"letter\": \"r\"}},\n",
        "            ],\n",
        "            # Turn 2: hypotenuse(e_count=9, r_count=5)\n",
        "            [{\"name\": \"calculator_tool\",\n",
        "              \"args\": {\"payload_json\": '{\"expr\":\"hypotenuse(9,5)\",\"precision\":6}'}}],\n",
        "            # Turn 3: circle_area(hypotenuse ~10.29563)\n",
        "            [{\"name\": \"calculator_tool\",\n",
        "              \"args\": {\"payload_json\":\n",
        "                       '{\"expr\":\"circle_area(10.295630)\",\"precision\":6}'}}],\n",
        "            # Turn 4: word_stats\n",
        "            [{\"name\": \"word_stats\",\n",
        "              \"args\": {\"text\": \"The elephant remembered everything effortlessly\"}}],\n",
        "            # Turn 5: final answer -- loop ends here (5 iterations consumed)\n",
        "            [],\n",
        "        ]\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for label, query, plan in TESTS:\n",
        "        sep = \"=\" * 60\n",
        "        print(f\"\\n{sep}\")\n",
        "        print(f\"TEST: {label}\")\n",
        "        print(sep)\n",
        "        run_agent(query, plan)"
      ],
      "metadata": {
        "id": "wmRWbED2Nd4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 5\n",
        "Rewrite the program so that runs a single long conversation instead of starting fresh with each call to run_agent.  Instead of a Python loop for the conversation, use LangGraph nodes and edges as you did in the exercises for Agent Orchestration Frameworks.  Include checkpointing and recovery.  Add to your porfolio a Mermaid diagram of the system and examples of a conversation that demonstrates tool use, the conversation context, and recovery."
      ],
      "metadata": {
        "id": "CyFEKMcDU7FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Task 5 – LangGraph Persistent Conversation Agent\n",
        "=================================================\n",
        "Architecture\n",
        "  • StateGraph with MessagesState – messages accumulate across ALL user turns\n",
        "  • Nodes  : agent  →  (conditional edge)  →  tools  →  agent  →  …  →  END\n",
        "  • Edge   : agent→tools (when tool_calls present), tools→agent (always),\n",
        "             agent→END (when no tool_calls)\n",
        "  • Checkpointing : MemorySaver (shared across graph instances → recovery demo)\n",
        "  • Recovery : re-compile graph with same MemorySaver; all history restored\n",
        "\n",
        "Tools (same four as Task 4)\n",
        "  1. get_weather    – simulated weather lookup\n",
        "  2. calculator     – arithmetic + geometric expressions (Task 3 calculator)\n",
        "  3. count_letter   – letter-frequency counter\n",
        "  4. word_stats     – word/sentence/unique-word + top-5 (custom tool)\n",
        "\n",
        "LLM layer\n",
        "  ScriptedLLM drives the conversation without API keys.\n",
        "  It is purely sequential: each call returns the next pre-written response,\n",
        "  supporting multi-step tool-chains within one user turn.\n",
        "  Swap USE_REAL_LLM = True to connect real OpenAI/Anthropic models.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "import json, math, ast, re, copy\n",
        "from typing import Any\n",
        "\n",
        "from langgraph.graph import StateGraph, MessagesState, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.messages import (\n",
        "    HumanMessage, AIMessage, ToolMessage, SystemMessage, BaseMessage\n",
        ")\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# PART 1 ─ Tool implementations\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "@tool\n",
        "def get_weather(location: str) -> str:\n",
        "    \"\"\"Get the current weather for a given city.\"\"\"\n",
        "    data = {\n",
        "        \"San Francisco\": \"Sunny, 72 F\",\n",
        "        \"New York\":      \"Cloudy, 55 F\",\n",
        "        \"London\":        \"Rainy, 48 F\",\n",
        "        \"Tokyo\":         \"Clear, 65 F\",\n",
        "    }\n",
        "    return data.get(location, f\"Weather data not available for {location}\")\n",
        "\n",
        "\n",
        "@tool\n",
        "def calculator(payload_json: str) -> str:\n",
        "    \"\"\"\n",
        "    Evaluate arithmetic and geometric expressions.\n",
        "    Pass JSON: '{\"expr\": \"circle_area(3)\", \"precision\": 4}'.\n",
        "    Supported: circle_area, circle_circumference, rectangle_area, triangle_area,\n",
        "    distance, hypotenuse, sin, cos, tan, sqrt, log, exp, pi, e, rad, deg.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        payload = json.loads(payload_json)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"ok\": False, \"error\": f\"Invalid JSON: {e}\"})\n",
        "    expr      = payload.get(\"expr\")\n",
        "    precision = payload.get(\"precision\")\n",
        "    if not isinstance(expr, str) or not expr.strip():\n",
        "        return json.dumps({\"ok\": False, \"error\": \"Missing expr.\"})\n",
        "\n",
        "    def circle_area(r):            return math.pi * r ** 2\n",
        "    def circle_circumference(r):   return 2 * math.pi * r\n",
        "    def rectangle_area(w, h):      return w * h\n",
        "    def triangle_area(b, h):       return 0.5 * b * h\n",
        "    def distance(x1, y1, x2, y2): return math.hypot(x2 - x1, y2 - y1)\n",
        "    def hypotenuse(a, b):          return math.hypot(a, b)\n",
        "    def rad(d):                    return math.radians(d)\n",
        "    def deg(r):                    return math.degrees(r)\n",
        "\n",
        "    env = {\n",
        "        \"pi\": math.pi, \"e\": math.e, \"abs\": abs, \"round\": round,\n",
        "        \"sin\": math.sin,   \"cos\": math.cos,   \"tan\": math.tan,\n",
        "        \"asin\": math.asin, \"acos\": math.acos, \"atan\": math.atan,\n",
        "        \"sqrt\": math.sqrt, \"log\": math.log,   \"log10\": math.log10,\n",
        "        \"exp\": math.exp,   \"pow\": pow,\n",
        "        \"circle_area\": circle_area, \"circle_circumference\": circle_circumference,\n",
        "        \"rectangle_area\": rectangle_area, \"triangle_area\": triangle_area,\n",
        "        \"distance\": distance, \"hypotenuse\": hypotenuse, \"rad\": rad, \"deg\": deg,\n",
        "    }\n",
        "    try:\n",
        "        try:    value = ast.literal_eval(expr)\n",
        "        except: value = eval(expr, {\"__builtins__\": {}}, env)\n",
        "        if isinstance(value, (int, float)) and isinstance(precision, int):\n",
        "            value = round(float(value), precision)\n",
        "        return json.dumps({\"ok\": True, \"result\": value, \"expr\": expr})\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"ok\": False, \"error\": str(e), \"expr\": expr})\n",
        "\n",
        "\n",
        "@tool\n",
        "def count_letter(text: str, letter: str) -> str:\n",
        "    \"\"\"Count how many times a single letter appears in text (case-insensitive).\"\"\"\n",
        "    if not letter or len(letter) != 1:\n",
        "        return json.dumps({\"ok\": False, \"error\": \"Provide exactly one letter.\"})\n",
        "    n = text.lower().count(letter.lower())\n",
        "    return json.dumps({\"ok\": True, \"letter\": letter.lower(),\n",
        "                       \"count\": n, \"text_length\": len(text)})\n",
        "\n",
        "\n",
        "@tool\n",
        "def word_stats(text: str) -> str:\n",
        "    \"\"\"Return word count, sentence count, unique words, top-5 frequent words.\"\"\"\n",
        "    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
        "    words     = re.findall(r\"[a-zA-Z']+\", text.lower())\n",
        "    freq: dict[str, int] = {}\n",
        "    for w in words:\n",
        "        freq[w] = freq.get(w, 0) + 1\n",
        "    top5 = sorted(freq.items(), key=lambda x: -x[1])[:5]\n",
        "    return json.dumps({\n",
        "        \"ok\": True,\n",
        "        \"word_count\": len(words), \"sentence_count\": len(sentences),\n",
        "        \"unique_word_count\": len(freq), \"top_5_words\": dict(top5),\n",
        "    })\n",
        "\n",
        "\n",
        "TOOLS   = [get_weather, calculator, count_letter, word_stats]\n",
        "tool_map = {t.name: t for t in TOOLS}\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# PART 2 ─ LLM layer\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def _tc(name: str, args: dict, n: int = 0) -> dict:\n",
        "    return {\"name\": name, \"args\": args, \"id\": f\"call_{name}_{n}\", \"type\": \"tool_call\"}\n",
        "\n",
        "\n",
        "# ── Pre-written script ────────────────────────────────────────────────────────\n",
        "# Each item = list of AIMessages that answer ONE human turn.\n",
        "# Multi-item turns model tool chains: first messages carry tool_calls,\n",
        "# last message is the final text answer.\n",
        "\n",
        "_SCRIPT: list[list[AIMessage]] = [\n",
        "    # Turn 0 – greeting, no tools\n",
        "    [AIMessage(content=(\n",
        "        \"Hello! I'm your assistant with four tools: weather lookup, a calculator \"\n",
        "        \"(supports geometry: circle_area, hypotenuse, distance, etc.), a letter \"\n",
        "        \"counter, and text statistics. How can I help?\"\n",
        "    ))],\n",
        "\n",
        "    # Turn 1 – single weather lookup\n",
        "    [\n",
        "        AIMessage(content=\"\", tool_calls=[\n",
        "            _tc(\"get_weather\", {\"location\": \"San Francisco\"})\n",
        "        ]),\n",
        "        AIMessage(content=(\n",
        "            \"San Francisco is currently Sunny, 72 F — perfect outdoor weather!\"\n",
        "        )),\n",
        "    ],\n",
        "\n",
        "    # Turn 2 – count one letter\n",
        "    [\n",
        "        AIMessage(content=\"\", tool_calls=[\n",
        "            _tc(\"count_letter\", {\"text\": \"Mississippi riverboats\", \"letter\": \"s\"})\n",
        "        ]),\n",
        "        AIMessage(content=(\n",
        "            \"There are **5** s's in 'Mississippi riverboats'.\"\n",
        "        )),\n",
        "    ],\n",
        "\n",
        "    # Turn 3 – parallel letter counts (i vs s)\n",
        "    [\n",
        "        AIMessage(content=\"\", tool_calls=[\n",
        "            _tc(\"count_letter\", {\"text\": \"Mississippi riverboats\", \"letter\": \"i\"}, 0),\n",
        "            _tc(\"count_letter\", {\"text\": \"Mississippi riverboats\", \"letter\": \"s\"}, 1),\n",
        "        ]),\n",
        "        AIMessage(content=(\n",
        "            \"i appears **4** times and s appears **5** times in \"\n",
        "            \"'Mississippi riverboats'. So there are MORE s's than i's.\"\n",
        "        )),\n",
        "    ],\n",
        "\n",
        "    # Turn 4 – sequential chain: parallel count_letter → calculator\n",
        "    [\n",
        "        AIMessage(content=\"\", tool_calls=[\n",
        "            _tc(\"count_letter\", {\"text\": \"Mississippi riverboats\", \"letter\": \"i\"}, 0),\n",
        "            _tc(\"count_letter\", {\"text\": \"Mississippi riverboats\", \"letter\": \"s\"}, 1),\n",
        "        ]),\n",
        "        AIMessage(content=\"\", tool_calls=[\n",
        "            _tc(\"calculator\", {\"payload_json\": '{\"expr\":\"sin(4-5)\",\"precision\":6}'}, 2),\n",
        "        ]),\n",
        "        AIMessage(content=(\n",
        "            \"i=4, s=5, difference=−1. sin(−1) ≈ **−0.841471**.\"\n",
        "        )),\n",
        "    ],\n",
        "\n",
        "    # Turn 5 – context recall (no tools)\n",
        "    [AIMessage(content=(\n",
        "        \"In this conversation we've checked weather for **San Francisco** \"\n",
        "        \"(Sunny, 72 F). We haven't looked up Tokyo yet — want me to?\"\n",
        "    ))],\n",
        "\n",
        "    # Turn 6 – all four tools; 3 parallel then 1 calculator\n",
        "    [\n",
        "        AIMessage(content=\"\", tool_calls=[\n",
        "            _tc(\"get_weather\",  {\"location\": \"Tokyo\"}, 0),\n",
        "            _tc(\"count_letter\", {\"text\": \"Tokyo is a wonderful metropolis\", \"letter\": \"o\"}, 1),\n",
        "            _tc(\"word_stats\",   {\"text\": \"Tokyo is a wonderful metropolis\"}, 2),\n",
        "        ]),\n",
        "        AIMessage(content=\"\", tool_calls=[\n",
        "            _tc(\"calculator\",\n",
        "                {\"payload_json\": '{\"expr\":\"circle_area(4)\",\"precision\":4}'}, 3),\n",
        "        ]),\n",
        "        AIMessage(content=(\n",
        "            \"Tokyo: Clear, 65 F. \"\n",
        "            \"'o' appears **4** times in the sentence. \"\n",
        "            \"Word stats: 5 words, 1 sentence, 5 unique words. \"\n",
        "            \"Circle area with radius=4 (the letter count): **50.2655** sq units.\"\n",
        "        )),\n",
        "    ],\n",
        "\n",
        "    # Turn 7 – deep 4-step sequential chain\n",
        "    [\n",
        "        AIMessage(content=\"\", tool_calls=[\n",
        "            _tc(\"count_letter\",\n",
        "                {\"text\": \"The elephant remembered everything effortlessly\", \"letter\": \"e\"}, 0),\n",
        "            _tc(\"count_letter\",\n",
        "                {\"text\": \"The elephant remembered everything effortlessly\", \"letter\": \"r\"}, 1),\n",
        "        ]),\n",
        "        AIMessage(content=\"\", tool_calls=[\n",
        "            _tc(\"calculator\",\n",
        "                {\"payload_json\": '{\"expr\":\"hypotenuse(11,4)\",\"precision\":6}'}, 2),\n",
        "        ]),\n",
        "        AIMessage(content=\"\", tool_calls=[\n",
        "            _tc(\"calculator\",\n",
        "                {\"payload_json\": '{\"expr\":\"circle_area(11.70470)\",\"precision\":6}'}, 3),\n",
        "        ]),\n",
        "        AIMessage(content=\"\", tool_calls=[\n",
        "            _tc(\"word_stats\",\n",
        "                {\"text\": \"The elephant remembered everything effortlessly\"}, 4),\n",
        "        ]),\n",
        "        AIMessage(content=(\n",
        "            \"In 'The elephant remembered everything effortlessly': \"\n",
        "            \"e=11, r=4. hypotenuse(11,4)≈11.7047. \"\n",
        "            \"circle_area(11.7047)≈430.529 sq units. \"\n",
        "            \"5 words, 1 sentence, 5 unique words. \"\n",
        "            \"That used all four tool types across 4 sequential tool steps!\"\n",
        "        )),\n",
        "    ],\n",
        "]\n",
        "\n",
        "\n",
        "class ScriptedLLM:\n",
        "    \"\"\"\n",
        "    Sequentially replays _SCRIPT.\n",
        "    • A new HumanMessage advances to the next script entry (outer pointer).\n",
        "    • A ToolMessage means a tool chain is in progress → advance inner pointer.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self._turn  = 0   # which script entry (= user turn)\n",
        "        self._inner = 0   # which AIMessage within the current entry\n",
        "\n",
        "    def invoke(self, messages: list[BaseMessage]) -> AIMessage:\n",
        "        last = messages[-1] if messages else None\n",
        "        last_is_tool = isinstance(last, ToolMessage)\n",
        "\n",
        "        if not last_is_tool:\n",
        "            # New human turn – advance outer pointer, reset inner\n",
        "            if self._turn < len(_SCRIPT):\n",
        "                pass   # already pointing at correct entry (advanced by caller)\n",
        "            self._inner = 0\n",
        "\n",
        "        entry  = _SCRIPT[min(self._turn, len(_SCRIPT) - 1)]\n",
        "        idx    = min(self._inner, len(entry) - 1)\n",
        "        result = copy.deepcopy(entry[idx])\n",
        "        self._inner += 1\n",
        "        return result\n",
        "\n",
        "    def next_turn(self):\n",
        "        \"\"\"Called by the harness before each new human message.\"\"\"\n",
        "        self._turn  = min(self._turn + 1, len(_SCRIPT) - 1)\n",
        "        self._inner = 0\n",
        "\n",
        "\n",
        "# Singleton so the same instance is shared across all graph invocations\n",
        "_SCRIPTED_LLM = ScriptedLLM()\n",
        "_SCRIPTED_LLM._turn = -1   # will be bumped to 0 on first next_turn()\n",
        "\n",
        "\n",
        "USE_REAL_LLM = False\n",
        "\n",
        "if USE_REAL_LLM:\n",
        "    try:\n",
        "        from langchain_openai import ChatOpenAI\n",
        "        _real_llm = ChatOpenAI(model=\"gpt-4o-mini\").bind_tools(TOOLS)\n",
        "    except ImportError:\n",
        "        from langchain_anthropic import ChatAnthropic\n",
        "        _real_llm = ChatAnthropic(model=\"claude-sonnet-4-20250514\").bind_tools(TOOLS)\n",
        "    def llm_invoke(messages): return _real_llm.invoke(messages)\n",
        "else:\n",
        "    def llm_invoke(messages): return _SCRIPTED_LLM.invoke(messages)\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# PART 3 ─ LangGraph nodes\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "SYSTEM = SystemMessage(content=(\n",
        "    \"You are a helpful assistant with four tools: get_weather, calculator, \"\n",
        "    \"count_letter, and word_stats.\\n\"\n",
        "    \"RULES: Always call calculator for any arithmetic; call count_letter for \"\n",
        "    \"letter counts; call word_stats for text statistics; call get_weather for \"\n",
        "    \"weather. Use full conversation history for context.\"\n",
        "))\n",
        "\n",
        "\n",
        "def agent_node(state: MessagesState) -> dict:\n",
        "    \"\"\"Invoke the LLM with the full message history.\"\"\"\n",
        "    msgs     = [SYSTEM] + state[\"messages\"]\n",
        "    response = llm_invoke(msgs)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "def tools_node(state: MessagesState) -> dict:\n",
        "    \"\"\"Execute all tool calls in the last AIMessage; return ToolMessages.\"\"\"\n",
        "    last_ai: AIMessage      = state[\"messages\"][-1]\n",
        "    results: list[ToolMessage] = []\n",
        "\n",
        "    for tc in last_ai.tool_calls:\n",
        "        name, args, tc_id = tc[\"name\"], tc[\"args\"], tc[\"id\"]\n",
        "        print(f\"    ⚙  {name}({args})\")\n",
        "\n",
        "        result = tool_map[name].invoke(args) if name in tool_map \\\n",
        "                 else f\"Error: unknown tool {name}\"\n",
        "\n",
        "        results.append(ToolMessage(content=str(result), tool_call_id=tc_id))\n",
        "\n",
        "    return {\"messages\": results}\n",
        "\n",
        "\n",
        "def should_continue(state: MessagesState) -> str:\n",
        "    \"\"\"Route: tool_calls present → 'tools', otherwise END.\"\"\"\n",
        "    last = state[\"messages\"][-1]\n",
        "    if isinstance(last, AIMessage) and getattr(last, \"tool_calls\", None):\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# PART 4 ─ Build graph\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def build_graph(checkpointer=None):\n",
        "    g = StateGraph(MessagesState)\n",
        "    g.add_node(\"agent\", agent_node)\n",
        "    g.add_node(\"tools\", tools_node)\n",
        "    g.set_entry_point(\"agent\")\n",
        "    g.add_conditional_edges(\"agent\", should_continue,\n",
        "                            {\"tools\": \"tools\", END: END})\n",
        "    g.add_edge(\"tools\", \"agent\")\n",
        "    return g.compile(checkpointer=checkpointer)\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# PART 5 ─ Conversation helpers\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def chat(app, thread_id: str, user_input: str) -> str:\n",
        "    \"\"\"Send one user message; advance scripted LLM turn; return reply.\"\"\"\n",
        "    _SCRIPTED_LLM.next_turn()\n",
        "\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "    inp    = {\"messages\": [HumanMessage(content=user_input)]}\n",
        "\n",
        "    print(f\"\\n{'─'*62}\")\n",
        "    print(f\"   {user_input}\")\n",
        "    print(f\"{'─'*62}\")\n",
        "\n",
        "    result = app.invoke(inp, config=config)\n",
        "    final  = result[\"messages\"][-1]\n",
        "    reply  = final.content if isinstance(final, AIMessage) else str(final)\n",
        "    print(f\"   {reply}\")\n",
        "    return reply\n",
        "\n",
        "\n",
        "def show_history(app, thread_id: str, label: str = \"\") -> None:\n",
        "    \"\"\"Pretty-print the full checkpoint message history.\"\"\"\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "    state  = app.get_state(config)\n",
        "    msgs   = state.values.get(\"messages\", [])\n",
        "    tag    = f\"  [{label}]\" if label else \"\"\n",
        "    print(f\"\\n{'═'*62}\")\n",
        "    print(f\"  CHECKPOINT HISTORY – thread '{thread_id}'{tag}\")\n",
        "    print(f\"  {len(msgs)} messages stored\")\n",
        "    print(f\"{'═'*62}\")\n",
        "    for i, m in enumerate(msgs):\n",
        "        role    = type(m).__name__.replace(\"Message\", \"\").upper()\n",
        "        snippet = (m.content or \"\")[:90].replace(\"\\n\", \" \")\n",
        "        tc_tag  = \"\"\n",
        "        if isinstance(m, AIMessage) and getattr(m, \"tool_calls\", None):\n",
        "            tc_tag = f\"  → [{', '.join(x['name'] for x in m.tool_calls)}]\"\n",
        "        print(f\"  [{i:02d}] {role:<8} {snippet}{tc_tag}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "def recover_and_continue(checkpointer, thread_id: str, user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Simulate a crash: build a brand-new graph instance using the EXISTING\n",
        "    checkpointer, confirm all history is restored, then continue the\n",
        "    conversation.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'*'*62}\")\n",
        "    print(f\"    SIMULATING CRASH — rebuilding graph from checkpoint …\")\n",
        "    app_new = build_graph(checkpointer)\n",
        "\n",
        "    config  = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "    state   = app_new.get_state(config)\n",
        "    n       = len(state.values.get(\"messages\", []))\n",
        "    print(f\"    RECOVERED: {n} messages restored from MemorySaver\")\n",
        "    print(f\"{'*'*62}\")\n",
        "\n",
        "    return chat(app_new, thread_id, user_input), app_new\n",
        "\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# PART 6 ─ Full demo\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def run_demo():\n",
        "    checkpointer = MemorySaver()\n",
        "    app          = build_graph(checkpointer)\n",
        "    TID          = \"portfolio-demo\"\n",
        "\n",
        "    print(\"═\"*62)\n",
        "    print(\"  Task 5 – LangGraph Persistent Conversation Agent\")\n",
        "    print(f\"  Thread: {TID}   |   Checkpointer: MemorySaver\")\n",
        "    print(\"═\"*62)\n",
        "\n",
        "    # ── Segment 1: basics ─────────────────────────────────────────────────────\n",
        "    print(\"\\n SEGMENT 1 – Greeting & single-tool weather lookup\")\n",
        "    chat(app, TID, \"Hello! What can you help me with?\")\n",
        "    chat(app, TID, \"What's the weather in San Francisco?\")\n",
        "\n",
        "    # ── Segment 2: letter counting ────────────────────────────────────────────\n",
        "    print(\"\\n SEGMENT 2 – Letter counting (single, then parallel)\")\n",
        "    chat(app, TID, \"How many s's are in 'Mississippi riverboats'?\")\n",
        "    chat(app, TID, \"Are there more i's than s's in 'Mississippi riverboats'?\")\n",
        "\n",
        "    # ── Segment 3: sequential chain ───────────────────────────────────────────\n",
        "    print(\"\\n SEGMENT 3 – Sequential chain: count_letter × 2 → calculator\")\n",
        "    chat(app, TID,\n",
        "         \"What is the sin of the difference between the number of i's \"\n",
        "         \"and s's in 'Mississippi riverboats'?\")\n",
        "\n",
        "    # ── Checkpoint snapshot before crash ─────────────────────────────────────\n",
        "    show_history(app, TID, label=\"before crash\")\n",
        "\n",
        "    # ── Crash + Recovery ──────────────────────────────────────────────────────\n",
        "    print(\"\\n SEGMENT 4 – Context recall + CRASH / RECOVERY\")\n",
        "    _, reply = \"dummy\", chat(app, TID,\n",
        "        \"Which city's weather have we looked up so far in this conversation?\")\n",
        "\n",
        "    # Now simulate a crash and rebuild from checkpoint\n",
        "    _, app = recover_and_continue(\n",
        "        checkpointer, TID,\n",
        "        \"What's the weather in Tokyo? Count the 'o' letters in \"\n",
        "        \"'Tokyo is a wonderful metropolis', get word stats for it, \"\n",
        "        \"and compute the circle area using the letter count as the radius.\"\n",
        "    )\n",
        "\n",
        "    # ── Segment 5: deep sequential chain ─────────────────────────────────────\n",
        "    print(\"\\n SEGMENT 5 – Deep 4-step sequential chain (all 4 tools)\")\n",
        "    chat(app, TID,\n",
        "         \"Count 'e' and 'r' in 'The elephant remembered everything effortlessly'. \"\n",
        "         \"Compute the hypotenuse of the right triangle whose legs are those counts. \"\n",
        "         \"Then compute the circle area with that hypotenuse as the radius. \"\n",
        "         \"Finally give me word stats for the sentence.\")\n",
        "\n",
        "    # ── Final checkpoint dump ─────────────────────────────────────────────────\n",
        "    show_history(app, TID, label=\"final — full conversation\")\n",
        "\n",
        "    print(\"[DEMO COMPLETE]\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_demo()"
      ],
      "metadata": {
        "id": "l3VHsfZXWeEt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}